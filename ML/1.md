监督学习

无监督学习

两者的区别为**是否需要人工参与数据标注**





##  监督学习(Supervised Learning)

教计算机如何去完成预测任务==（有反馈）==，<u>预先给一定数据量的输入</u>和<u>对应的结果</u>，建模拟合，最后让计算机预测未知数据的结果。

##### 1.回归问题(Regression): 回归问题即为预测一系列的==**连续值**==

在房屋价格预测的例子中，给出了一系列的房屋面基数据，根据这些数据来预测任意面积的房屋价格。给出照片-年龄数据集，预测给定照片的年龄。

**2.分类问题(Classification)**:分类问题即为预测一系列的==离散值==

即根据数据预测被预测对象属于哪个分类,视频中举了癌症肿瘤这个例子，针对诊断结果，分别分类为良性或恶性。还例如垃圾邮件分类问题，也同样属于监督学习中的分类问题





## 无监督学习(Unsupervised Learning)

相对于监督学习，训练集不会有人为标注的结果==（无反馈）==，我们不会给出结果或无法得知训练集的结果是什么样，而是单纯由计算机通过无监督学习算法自行分析，从而“得出结果”。计算机可能会把特定的数据集归为几个不同的簇，故叫做聚类算法。

1.比如聚类问题

2.**新闻聚合**

 



## 单变量线性回归(Linear Regression with One Variable)

==个人理解：给定一个问题模型，即：给定了输入x和输出y，预测结果，预测量是连续的，是一个线性回归问题。通过输入输出可以拟合出很多假设的模型H(x)。再引入损失函数(Cost Function)概念，用于度量建模误差：==  **个人理解损失函数就是代价函数，即最小化预测模型与实际给定训练集合之间的误差。 通常会采用平方损失函数（最小二乘法）**

![image-20181220133357005](/Users/test/Downloads/7-TestCode/__notebook/ML/image-20181220133357005-5284037.png)

![image-20181220133005734](/Users/test/Downloads/7-TestCode/__notebook/ML/image-20181220133005734-5283805.png)





## 梯度下降

梯度下降背后的思想是：开始时，我们随机选择一个参数组合即起始点 ，计算损失函数失函数，然后寻找下一个能使得损失函数下降最多的参数组合。不断迭代，直到找到一个局部最小值(local minimum)，由于下降的情况只考虑当前参数组合周围的情况，所以无法确定当前的局部最小值是否就是全局最小值(global minimum)，不同的初始参数组合，可能会产生不同的局部最小值。

个人理解：简单的梯度下降算法，步长太小收敛可能比较慢，步长太大收敛可能越过最低点，导致无法收敛